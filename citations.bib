@article{DualTime,
  author={Weiqi Zhang and
                  Jiexia Ye and
                  Ziyue Li and
                  Jia Li and
                  Fugee Tsung},
  title={DualTime: {A} Dual-Adapter Multimodal Language Model for Time Series Representation},
  journal={ArXiv},
  volume={abs/2406.06620},
  year={2024}
}

@article{TimeCMA,
  author={Chenxi Liu and
                  Qianxiong Xu and
                  Hao Miao and
                  Sun Yang and
                  Lingzheng Zhang and
                  Cheng Long and
                  Ziyue Li and
                  Rui Zhao},
  title={TimeCMA: Towards LLM-Empowered Time Series Forecasting via Cross-Modality Alignment},
  journal={ArXiv},
  volume={abs/2406.01638},
  year={2024}
}

@inproceedings{aLLM4TS,
  author={Yuxuan Bian and
                  Xuan Ju and
                  Jiangtong Li and
                  Zhijian Xu and
                  Dawei Cheng and
                  Qiang Xu},
  title={Multi-Patch Prediction: Adapting Language Models for Time Series Representation Learning},
  booktitle ={{ICML}},
  year={2024}
}

@article{LLM4TS,
  author={Ching Chang and
                  Wen{-}Chih Peng and
                  Tien{-}Fu Chen},
  title={{LLM4TS:} Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs},
  journal={ArXiv},
  volume={abs/2308.08469},
  year={2023}
}

@inproceedings{TEST,
  author={Chenxi Sun and
                  Hongyan Li and
                  Yaliang Li and
                  Shenda Hong},
  title={{TEST:} Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series},
  booktitle ={{ICLR}},
  year={2024}
}

@article{PromptCast,
  author={Hao Xue and
                  Flora D. Salim},
  title={PromptCast: {A} New Prompt-Based Learning Paradigm for Time Series
                  Forecasting},
  journal={{TKDE}},
  volume={36},
  number={11},
  pages={6851--6864},
  year={2024}
}

@inproceedings{DeWave,
  author={Yiqun Duan and
                  Charles Chau and
                  Zhen Wang and
                  Yu{-}Kai Wang and
                  Chin{-}Teng Lin},
  title={DeWave: Discrete Encoding of {EEG} Waves for {EEG} to Text Translation},
  booktitle ={{NeurIPS}},
  year={2023}
}

@inproceedings{GenG,
  author={Xiaomao Zhou and
                  Qingmin Jia and
                  Yujiao Hu and
                  Renchao Xie and
                  Tao Huang and
                  F. Richard Yu},
  title={GenG: An LLM-Based Generic Time Series Data Generation Approach for
                  Edge Intelligence via Cross-Domain Collaboration},
  booktitle ={{INFOCOM}},
  pages={1--6},
  year={2024}
}

@inproceedings{S2IP-LLM,
  author={Zijie Pan and
                  Yushan Jiang and
                  Sahil Garg and
                  Anderson Schneider and
                  Yuriy Nevmyvaka and
                  Dongjin Song},
  title={{S2IP-LLM:} Semantic Space Informed Prompt Learning with {LLM} for Time Series Forecasting},
  booktitle ={{ICML}},
  year={2024}
}

@inproceedings{TIME-LLM,
  author={Ming Jin and
                  Shiyu Wang and
                  Lintao Ma and
                  Zhixuan Chu and
                  James Y. Zhang and
                  Xiaoming Shi and
                  Pin{-}Yu Chen and
                  Yuxuan Liang and
                  Yuan{-}Fang Li and
                  Shirui Pan and
                  Qingsong Wen},
  title={Time-LLM: Time Series Forecasting by Reprogramming Large Language Models},
  booktitle ={{ICLR}},
  year={2024}
}

@inproceedings{GPT4MTS,
  author={Furong Jia and
                  Kevin Wang and
                  Yixiang Zheng and
                  Defu Cao and
                  Yan Liu},
  editor={Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title={{GPT4MTS:} Prompt-based Large Language Model for Multimodal Time-series Forecasting},
  booktitle ={{AAAI}},
  pages={23343--23351},
  year={2024}
}

@inproceedings{LLMTime,
  author={Nate Gruver and
                  Marc Finzi and
                  Shikai Qiu and
                  Andrew Gordon Wilson},
  title={Large Language Models Are Zero-Shot Time Series Forecasters},
  booktitle ={{NeurIPS}},
  year={2023}
}

@inproceedings{GPT4TS,
  author={Tian Zhou and
                  Peisong Niu and
                  Xue Wang and
                  Liang Sun and
                  Rong Jin},
  title={One Fits All: Power General Time Series Analysis by Pretrained {LM}},
  booktitle ={{NeurIPS}},
  year={2023}
}

@inproceedings{MATM,
  author={Jielin Qiu and
                  William Han and
                  Jiacheng Zhu and
                  Mengdi Xu and
                  Douglas Weber and
                  Bo Li and
                  Ding Zhao},
  title={Can Brain Signals Reveal Inner Alignment with Human Languages?},
  booktitle ={{EMNLP}},
  pages={1789--1804},
  year={2023}
}

@inproceedings{JoLT,
  title={Jolt: Jointly learned representations of language and time- series},
  author={Cai, Yifu and Goswami, Mononito and Choudhry, Arjun and Srinivasan, Arvind and Dubrawski, Artur},
  booktitle={{NeurIPS}},
  year={2023}
}

@article{ECG-LLM,
  title={Transfer knowledge from natural language to electrocardiography: Can we detect cardiovascular disease through language models?},
  author={Qiu, Jielin and Han, William and Zhu, Jiacheng and Xu, Mengdi and Rosenberg, Michael and Liu, Emerson and Weber, Douglas and Zhao, Ding},
  journal={ArXiv},
  volume={ArXiv:2301.09017},
  year={2023}
}

@article{TENT,
  title={Tent: Connect language models with iot sensors for zero-shot activity recognition},
  author={Zhou, Yunjiao and Yang, Jianfei and Zou, Han and Xie, Lihua},
  journal={ArXiv},
  volume={ArXiv:2311.08245},
  year={2023}
}

@article{K-Link,
  title={K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data},
  author={Wang, Yucheng and Jin, Ruibing and Wu, Min and Li, Xiaoli and Xie, Lihua and Chen, Zhenghua},
  journal={ArXiv},
  volume={ArXiv:2403.03645},
  year={2024}
}

@inproceedings{TEMPO-GPT,
  author={Defu Cao and
                  Furong Jia and
                  Sercan {\"{O}}. Arik and
                  Tomas Pfister and
                  Yixiang Zheng and
                  Wen Ye and
                  Yan Liu},
  title={{TEMPO:} Prompt-based Generative Pre-trained Transformer for Time
                  Series Forecasting},
  booktitle ={{ICLR}},
  year={2024}
}

@article{TSFLLMs,
  author={Mingyu Jin and
                  Hua Tang and
                  Chong Zhang and
                  Qinkai Yu and
                  Chengzhi Liu and
                  Suiyuan Zhu and
                  Yongfeng Zhang and
                  Mengnan Du},
  title={Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities},
  journal={ArXiv},
  volume={abs/2402.10835},
  year={2024}
}

@article{Instruct-FinGPT,
  author={Boyu Zhang and
                  Hongyang Yang and
                  Xiao{-}Yang Liu},
  title={Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models},
  journal={ArXiv},
  volume={abs/2306.12659},
  year={2023}
}

@misc{BloombergGPT,
      title={BloombergGPT: A Large Language Model for Finance}, 
      author={Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann},
      year={2023},
      archivePrefix={ArXiv},
      volume={abs/2303.17564}
}

@article{yu2023temporal,
  author={Xinli Yu and
                  Zheng Chen and
                  Yuan Ling and
                  Shujing Dong and
                  Zongyi Liu and
                  Yanbin Lu},
  title={Temporal Data Meets {LLM} - Explainable Financial Time Series Forecasting},
  journal={ArXiv},
  volume={abs/2306.11025},
  year={2023}
}

@article{lopez-lira2023can,
  title={Can chatgpt forecast stock price movements? return predictability and large language models},
  author={Lopez-Lira, Alejandro and Tang, Yuehua},
  journal={ArXiv},
  volume={ArXiv:2304.07619},
  year={2023}
}

@article{xie2023the,
  author={Qianqian Xie and
                  Weiguang Han and
                  Yanzhao Lai and
                  Min Peng and
                  Jimin Huang},
  title={The Wall Street Neophyte: {A} Zero-Shot Analysis of ChatGPT Over MultiModal
                  Stock Movement Prediction Challenges},
  journal={ArXiv},
  volume={abs/2304.05351},
  year={2023}
}

@article{NYUTron,
  title={Health system-scale language models are all-purpose prediction engines},
  author={Jiang, Lavender Yao and Liu, Xujin Chris and Nejatian, Nima Pour and Nasir-Moin, Mustafa and Wang, Duo and Abidin, Anas and Eaton, Kevin and Riina, Howard Antony and Laufer, Ilya and Punjabi, Paawan and others},
  journal={Nature},
  volume={619},
  number={7969},
  pages={357--362},
  year={2023}
}

@inproceedings{METS,
  title={Frozen language model helps ecg zero-shot learning},
  author={Li, Jun and Liu, Che and Cheng, Sibo and Arcucci, Rossella and Hong, Shenda},
  booktitle={Medical Imaging with Deep Learning},
  pages={402--415},
  year={2024}
}

@misc{METS1,
      title={Frozen Language Model Helps ECG Zero-Shot Learning}, 
      author={Jun Li and Che Liu and Sibo Cheng and Rossella Arcucci and Shenda Hong},
      journal={ArXiv},
      volume={abs/2303.12311},
      year={2023}
}

@article{liu2023large,
  title={Large language models are few-shot health learners},
  author={Liu, Xin and McDuff, Daniel and Kovacs, Geza and Galatzer-Levy, Isaac and Sunshine, Jacob and Zhan, Jiening and Poh, Ming-Zher and Liao, Shun and Di Achille, Paolo and Patel, Shwetak},
  journal={ArXiv},
  volume={abs/2305.15525},
  year={2023}
}

@article{GatorTron,
  author={Xi Yang and
                  Aokun Chen and
                  Nima M. Pournejatian and
                  Hoo Chang Shin and
                  Kaleb E. Smith and
                  Christopher Parisien and
                  Colin Compas and
                  Cheryl Martin and
                  Anthony B. Costa and
                  Mona G. Flores and
                  Ying Zhang and
                  Tanja Magoc and
                  Christopher A. Harle and
                  Gloria P. Lipori and
                  Duane A. Mitchell and
                  William R. Hogan and
                  Elizabeth A. Shenkman and
                  Jiang Bian and
                  Yonghui Wu},
  title={A large language model for electronic health records},
  journal={npj Digit. Medicine},
  volume={5},
  year={2022}
}

@inproceedings{ETP,
  author={Che Liu and
                  Zhongwei Wan and
                  Sibo Cheng and
                  Mi Zhang and
                  Rossella Arcucci},
  title={{ETP:} Learning Transferable {ECG} Representations via ECG-Text Pre-Training},
  booktitle ={{ICASSP}},
  pages={8230--8234},
  year={2024}
}

@inproceedings{SHARE,
  author={Xiyuan Zhang and
                  Ranak Roy Chowdhury and
                  Jiayun Zhang and
                  Dezhi Hong and
                  Rajesh K. Gupta and
                  Jingbo Shang},
  title={Unleashing the Power of Shared Label Structures for Human Activity
                  Recognition},
  booktitle ={{CIKM}},
  pages={3340--3350},
  year={2023}
}

@inproceedings{Survey-Foundation,
  author={Yuxuan Liang and
                  Haomin Wen and
                  Yuqi Nie and
                  Yushan Jiang and
                  Ming Jin and
                  Dongjin Song and
                  Shirui Pan and
                  Qingsong Wen},
  title={Foundation Models for Time Series Analysis: {A} Tutorial and Survey},
  booktitle ={{SIGKDD}},
  pages={6555--6565},
  year={2024}
}

@inproceedings{Survey-Empowering,
  author={Yushan Jiang and
                  Zijie Pan and
                  Xikun Zhang and
                  Sahil Garg and
                  Anderson Schneider and
                  Yuriy Nevmyvaka and
                  Dongjin Song},
  title={Empowering Time Series Analysis with Large Language Models: {A} Survey},
  booktitle ={{IJCAI}},
  pages={8095--8103},
  year={2024}
}

@inproceedings{Survey-LLMTS,
  author={Xiyuan Zhang and
                  Ranak Roy Chowdhury and
                  Rajesh K. Gupta and
                  Jingbo Shang},
  title={Large Language Models for Time Series: {A} Survey},
  booktitle ={{IJCAI}},
  pages={8335--8343},
  year={2024}
}

@inproceedings{Survey-Transformer,
  author={Qingsong Wen and
                  Tian Zhou and
                  Chaoli Zhang and
                  Weiqi Chen and
                  Ziqing Ma and
                  Junchi Yan and
                  Liang Sun},
  title={Transformers in Time Series: {A} Survey},
  booktitle ={{IJCAI}},
  pages={6778--6786},
  year={2023}
}

@inproceedings{Survey-DeepLearning,
  author={Qingsong Wen and
                  Liang Sun and
                  Fan Yang and
                  Xiaomin Song and
                  Jingkun Gao and
                  Xue Wang and
                  Huan Xu},
  title={Time Series Data Augmentation for Deep Learning: {A} Survey},
  booktitle ={{IJCAI}},
  pages={4653--4660},
  year={2021}
}

@article{Survey-TSData,
  author={Ming Jin and
                  Qingsong Wen and
                  Yuxuan Liang and
                  Chaoli Zhang and
                  Siqiao Xue and
                  Xue Wang and
                  James Zhang and
                  Yi Wang and
                  Haifeng Chen and
                  Xiaoli Li and
                  Shirui Pan and
                  Vincent S. Tseng and
                  Yu Zheng and
                  Lei Chen and
                  Hui Xiong},
  title={Large Models for Time Series and Spatio-Temporal Data: {A} Survey
                  and Outlook},
  journal={ArXiv},
  volume={abs/2310.10196},
  year={2023}
}

@article{Survey-pretrainedModel,
  author={Qianli Ma and
                  Zhen Liu and
                  Zhenjing Zheng and
                  Ziyang Huang and
                  Siying Zhu and
                  Zhongzhong Yu and
                  James T. Kwok},
  title={A Survey on Time-Series Pre-Trained Models},
  journal={{TKDE}},
  volume={36},
  number={12},
  pages={7536--7555},
  year={2024}
}


@article{Survey_MLLM,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={National Science Review},
  pages={405--409},
  year={2024}
}

@misc{Survey_Representation,
    title={A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Model}, 
    author={Jiexia Ye and Weiqi Zhang and Ke Yi and Yongzi Yu and Ziyue Li and Jia Li and Fugee Tsung},
    journal={ArXiv},      
    year={2024}
}

@article{Llama3,
  author={Abhimanyu Dubey and
                  Abhinav Jauhri and
                  others},
  title={The Llama 3 Herd of Models},
  journal={ArXiv},
  volume={abs/2407.21783},
  year={2024}
}

@article{Llama3_1,
  author={Abhimanyu Dubey and
                  Abhinav Jauhri and
                  Abhinav Pandey and
                  Abhishek Kadian and
                  Ahmad Al{-}Dahle and
                  Aiesha Letman and
                  Akhil Mathur and
                  Alan Schelten and
                  Amy Yang and
                  Angela Fan and
                  Anirudh Goyal and
                  Anthony Hartshorn and
                  Aobo Yang and
                  Archi Mitra and
                  Archie Sravankumar and
                  Artem Korenev and
                  Arthur Hinsvark and
                  Arun Rao and
                  Aston Zhang and
                  Aur{\'{e}}lien Rodriguez and
                  Austen Gregerson and
                  Ava Spataru and
                  Baptiste Rozi{\`{e}}re and
                  Bethany Biron and
                  Binh Tang and
                  Bobbie Chern and
                  Charlotte Caucheteux and
                  Chaya Nayak and
                  Chloe Bi and
                  Chris Marra and
                  Chris McConnell and
                  Christian Keller and
                  Christophe Touret and
                  Chunyang Wu and
                  Corinne Wong and
                  Cristian Canton Ferrer and
                  Cyrus Nikolaidis and
                  Damien Allonsius and
                  Daniel Song and
                  Danielle Pintz and
                  Danny Livshits and
                  David Esiobu and
                  Dhruv Choudhary and
                  Dhruv Mahajan and
                  Diego Garcia{-}Olano and
                  Diego Perino and
                  Dieuwke Hupkes and
                  Egor Lakomkin and
                  Ehab AlBadawy and
                  Elina Lobanova and
                  Emily Dinan and
                  Eric Michael Smith and
                  Filip Radenovic and
                  Frank Zhang and
                  Gabriel Synnaeve and
                  Gabrielle Lee and
                  Georgia Lewis Anderson and
                  Graeme Nail and
                  Gr{\'{e}}goire Mialon and
                  Guan Pang and
                  Guillem Cucurell and
                  Hailey Nguyen and
                  Hannah Korevaar and
                  Hu Xu and
                  Hugo Touvron and
                  Iliyan Zarov and
                  Imanol Arrieta Ibarra and
                  Isabel M. Kloumann and
                  Ishan Misra and
                  Ivan Evtimov and
                  Jade Copet and
                  Jaewon Lee and
                  Jan Geffert and
                  Jana Vranes and
                  Jason Park and
                  Jay Mahadeokar and
                  Jeet Shah and
                  Jelmer van der Linde and
                  Jennifer Billock and
                  Jenny Hong and
                  Jenya Lee and
                  Jeremy Fu and
                  Jianfeng Chi and
                  Jianyu Huang and
                  Jiawen Liu and
                  Jie Wang and
                  Jiecao Yu and
                  Joanna Bitton and
                  Joe Spisak and
                  Jongsoo Park and
                  Joseph Rocca and
                  Joshua Johnstun and
                  Joshua Saxe and
                  Junteng Jia and
                  Kalyan Vasuden Alwala and
                  Kartikeya Upasani and
                  Kate Plawiak and
                  Ke Li and
                  Kenneth Heafield and
                  Kevin Stone and
                  et al.},
  title={The Llama 3 Herd of Models},
  journal={ArXiv},
  volume={abs/2407.21783},
  year={2024}
}

@article{GPT-4,
  author={OpenAI},
  title={{GPT-4} Technical Report},
  journal={ArXiv},
  volume={abs/2303.08774},
  year={2023}
}

@article{PaLM,
  author={Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  others},
  title={PaLM: Scaling Language Modeling with Pathways},
  journal={J. Mach. Learn. Res.},
  volume={24},
  pages={240:1--240:113},
  year={2023}
}


@article{PaLM1,
  author={Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  Maarten Bosma and
                  Gaurav Mishra and
                  Adam Roberts and
                  Paul Barham and
                  Hyung Won Chung and
                  Charles Sutton and
                  Sebastian Gehrmann and
                  Parker Schuh and
                  Kensen Shi and
                  Sasha Tsvyashchenko and
                  Joshua Maynez and
                  Abhishek Rao and
                  Parker Barnes and
                  Yi Tay and
                  Noam Shazeer and
                  Vinodkumar Prabhakaran and
                  Emily Reif and
                  Nan Du and
                  Ben Hutchinson and
                  Reiner Pope and
                  James Bradbury and
                  Jacob Austin and
                  Michael Isard and
                  Guy Gur{-}Ari and
                  Pengcheng Yin and
                  Toju Duke and
                  Anselm Levskaya and
                  Sanjay Ghemawat and
                  Sunipa Dev and
                  Henryk Michalewski and
                  Xavier Garcia and
                  Vedant Misra and
                  Kevin Robinson and
                  Liam Fedus and
                  Denny Zhou and
                  Daphne Ippolito and
                  David Luan and
                  Hyeontaek Lim and
                  Barret Zoph and
                  Alexander Spiridonov and
                  Ryan Sepassi and
                  David Dohan and
                  Shivani Agrawal and
                  Mark Omernick and
                  Andrew M. Dai and
                  Thanumalayan Sankaranarayana Pillai and
                  Marie Pellat and
                  Aitor Lewkowycz and
                  Erica Moreira and
                  Rewon Child and
                  Oleksandr Polozov and
                  Katherine Lee and
                  Zongwei Zhou and
                  Xuezhi Wang and
                  Brennan Saeta and
                  Mark Diaz and
                  Orhan Firat and
                  Michele Catasta and
                  Jason Wei and
                  Kathy Meier{-}Hellstern and
                  Douglas Eck and
                  Jeff Dean and
                  Slav Petrov and
                  Noah Fiedel},
  title={PaLM: Scaling Language Modeling with Pathways},
  journal={J. Mach. Learn. Res.},
  volume={24},
  pages={240:1--240:113},
  year={2023}
}


@article{ChatGML,
  author={Aohan Zeng and
                  Bin Xu and
                  Bowen Wang
                  and others},
  title={ChatGLM: {A} Family of Large Language Models from {GLM-130B} to {GLM-4} All Tools},
  journal={ArXiv},
  volume={abs/2406.12793},
  year={2024}
}


@article{ChatGML1,
  author={Aohan Zeng and
                  Bin Xu and
                  Bowen Wang and
                  Chenhui Zhang and
                  Da Yin and
                  Diego Rojas and
                  Guanyu Feng and
                  Hanlin Zhao and
                  Hanyu Lai and
                  Hao Yu and
                  Hongning Wang and
                  Jiadai Sun and
                  Jiajie Zhang and
                  Jiale Cheng and
                  Jiayi Gui and
                  Jie Tang and
                  Jing Zhang and
                  Juanzi Li and
                  Lei Zhao and
                  Lindong Wu and
                  Lucen Zhong and
                  Mingdao Liu and
                  Minlie Huang and
                  Peng Zhang and
                  Qinkai Zheng and
                  Rui Lu and
                  Shuaiqi Duan and
                  Shudan Zhang and
                  Shulin Cao and
                  Shuxun Yang and
                  Weng Lam Tam and
                  Wenyi Zhao and
                  Xiao Liu and
                  Xiao Xia and
                  Xiaohan Zhang and
                  Xiaotao Gu and
                  Xin Lv and
                  Xinghan Liu and
                  Xinyi Liu and
                  Xinyue Yang and
                  Xixuan Song and
                  Xunkai Zhang and
                  Yifan An and
                  Yifan Xu and
                  Yilin Niu and
                  Yuantao Yang and
                  Yueyan Li and
                  Yushi Bai and
                  Yuxiao Dong and
                  Zehan Qi and
                  Zhaoyu Wang and
                  Zhen Yang and
                  Zhengxiao Du and
                  Zhenyu Hou and
                  Zihan Wang},
  title={ChatGLM: {A} Family of Large Language Models from {GLM-130B} to {GLM-4} All Tools},
  journal={ArXiv},
  volume={abs/2406.12793},
  year={2024}
}

@article{GPT-2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{BERT,
  author={Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title={{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle ={{NAACL-HLT}},
  pages={4171--4186},
  year={2019}
}

@article{T5,
  author={Colin Raffel and
                  Noam Shazeer and
                  Adam Roberts and
                  Katherine Lee and
                  Sharan Narang and
                  Michael Matena and
                  Yanqi Zhou and
                  Wei Li and
                  Peter J. Liu},
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal={J. Mach. Learn. Res.},
  volume={21},
  pages={140:1--140:67},
  year={2020}
}

@misc{DeepSeek-V3,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and others},
      year={2024},
      journal={ArXiv},
      volume={abs/2412.19437}
}

@misc{DeepSeek-V31,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T. Wang and Tao Yun and Tian Pei and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and Y. K. Li and Y. Q. Wang and Y. X. Wei and Y. X. Zhu and Yang Zhang and Yanhong Xu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yu Wu and Yuan Ou and Yuchen Zhu and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yukun Zha and Yunfan Xiong and Yunxian Ma and Yuting Yan and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Z. F. Wu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhibin Gou and Zhicheng Ma and Zhigang Yan and Zhihong Shao and Zhipeng Xu and Zhiyu Wu and Zhongyu Zhang and Zhuoshu Li and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Ziyi Gao and Zizheng Pan},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}

@misc{Claude-3.5-sonnet,
      title={Claude 3.5 sonnet}, 
      author={Anthropic},
      year={2024},
      url={https://www.anthropic.com/news/claude-3-5-sonnet.}
}

@misc{TimeGPT-1,
      title={TimeGPT-1}, 
      author={Azul Garza and Cristian Challu and Max Mergenthaler-Canseco},
      journal={ArXiv},
      volume={abs/2310.03589},
      year={2023}
}

@article{Time-MoE,
      title={Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts}, 
      author={Xiaoming Shi and
                  Shiyu Wang and
                  Yuqi Nie and
                  Dianqi Li and
                  Zhou Ye and
                  Qingsong Wen and
                  Ming Jin},
      journal={ArXiv},
      volume={abs/2409.16040},
      year={2024}
}

@inproceedings{Patch,
  author={Yuqi Nie and
                  Nam H. Nguyen and
                  Phanwadee Sinthong and
                  Jayant Kalagnanam},
  title={A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  booktitle ={{ICLR}},
  year={2023}
}

@inproceedings{Linear,
  author={Ailing Zeng and
                  Muxi Chen and
                  Lei Zhang and
                  Qiang Xu},
  editor={Brian Williams and
                  Yiling Chen and
                  Jennifer Neville},
  title={Are Transformers Effective for Time Series Forecasting?},
  booktitle ={{AAAI}},
  pages={11121--11128},
  year={2023}
}


@inproceedings{iTransformer,
  author={Yong Liu and
                  Tengge Hu and
                  Haoran Zhang and
                  Haixu Wu and
                  Shiyu Wang and
                  Lintao Ma and
                  Mingsheng Long},
  title={iTransformer: Inverted Transformers Are Effective for Time Series
                  Forecasting},
  booktitle ={{ICLR}},
  year={2024}
}

@inproceedings{Transformer,
  author={Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  editor={Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title={Attention is All you Need},
  booktitle ={{NeurIPS}},
  pages={5998--6008},
  year={2017}
}

# add by leeway
@article{AutoTimes,
  author={Yong Liu and
                  Guo Qin and
                  Xiangdong Huang and
                  Jianmin Wang and
                  Mingsheng Long},
  title={AutoTimes: Autoregressive Time Series Forecasters via Large Language
                  Models},
  journal={ArXiv},
  volume={abs/2402.02370},
  year={2024}
}

@inproceedings{LeRet,
  author={Qihe Huang and
                  Zhengyang Zhou and
                  Kuo Yang and
                  Gengyu Lin and
                  Zhongchao Yi and
                  Yang Wang},
  title={LeRet: Language-Empowered Retentive Network for Time Series Forecasting},
  booktitle ={{IJCAI}},
  pages={4165--4173},
  year={2024}
}

@misc{LeMoLE,
      title={LeMoLE: LLM-Enhanced Mixture of Linear Experts for Time Series Forecasting}, 
      author={Lingzheng Zhang and Lifeng Shen and Yimin Zheng and Shiyuan Piao and Ziyue Li and Fugee Tsung},
      year={2024},
      journal={ArXiv},
      volume={abs/2412.00053}
}

@misc{LLM-ABBA,
      title={LLM-ABBA: Understanding time series via symbolic approximation}, 
      author={Erin Carson and Xinye Chen and Cheng Kang},
      year={2024},
      journal={ArXiv},
      volume={abs/2411.18506} 
}

@misc{MedTsLLM,
      title={MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis}, 
      author={Nimeesha Chan and Felix Parker and William Bennett and Tianyi Wu and Mung Yao Jia and James Fackler and Kimia Ghobadi},
      year={2024},
      journal={ArXiv},
      volume={abs/2408.07773}
}

@misc{XForecast,
      title={XForecast: Evaluating Natural Language Explanations for Time Series Forecasting}, 
      author={Taha Aksu and Chenghao Liu and Amrita Saha and Sarah Tan and Caiming Xiong and Doyen Sahoo},
      year={2024},
      journal={ArXiv},
      volume={abs/2410.14180}
}

@misc{HiTime,
      title={Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification}, 
      author={Xiaoyu Tao and Tingyue Pan and Mingyue Cheng and Yucong Luo},
      year={2024},
      journal={ArXiv},
      volume={abs/2410.18686} 
}

@misc{TS-TCD,
      title={TS-TCD: Triplet-Level Cross-Modal Distillation for Time-Series Forecasting Using Large Language Models}, 
      author={Pengfei Wang and Huanran Zheng and Silong Dai and Wenjing Yue and Wei Zhu and Xiaoling Wang},
      year={2024},
      journal={ArXiv},
      volume={abs/2409.14978} 
}

@misc{CALF,
      title={CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning}, 
      author={Peiyuan Liu and Hang Guo and Tao Dai and Naiqi Li and Jigang Bao and Xudong Ren and Yong Jiang and Shu-Tao Xia},
      journal={ArXiv},
      volume={abs/2403.07300},
      year={2024} 
}

@misc{ChatTime,
      title={ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data}, 
      author={Chengsen Wang and Qi Qi and Jingyu Wang and Haifeng Sun and Zirui Zhuang and Jinming Wu and Lei Zhang and Jianxin Liao},
      journal={ArXiv},
      volume={abs/2412.11376},
      year={2024}
}

@misc{ChatTS,
      title={ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning}, 
      author={Zhe Xie and Zeyan Li and Xiao He and Longlong Xu and Xidao Wen and Tieying Zhang and Jianjun Chen and Rui Shi and Dan Pei},
      journal={ArXiv},
      volume={abs/2412.03104},
      year={2024}
}

@misc{ExplicitAdapters4TS,
      title={Understanding the Role of Textual Prompts in LLM for Time Series Forecasting: an Adapter View}, 
      author={Peisong Niu and Tian Zhou and Xue Wang and Liang Sun and Rong Jin},
      journal={ArXiv},
      volume={abs/2311.14782},
      year={2024}
}

@misc{SensorLLM,
      title={SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition}, 
      author={Zechen Li and Shohreh Deldari and Linyao Chen and Hao Xue and Flora D. Salim},
      journal={ArXiv},
      volume={abs/2410.10624},
      year={2024}
}

@misc{LLM-TS-Integrator,
      title={LLM-TS Integrator: Integrating LLM for Enhanced Time Series Modeling}, 
      author={Can Chen and Gabriel Oliveira and Hossein Sharifi Noghabi and Tristan Sylvain},
      journal={ArXiv},
      volume={abs/2410.16489},
      year={2024}
}

@misc{FedTime,
      title={A federated large language model for long-term time series forecasting}, 
      author={Raed Abdel-Sater and A. Ben Hamza},
      journal={ArXiv},
      volume={abs/2407.20503},
      year={2024}
}

# dataset
@article{Dataset-ECGQA,
  title={Ecg-qa: A comprehensive question answering dataset combined with electrocardiogram},
  author={Oh, Jungwoo and Lee, Gyubok and Bae, Seongsu and Kwon, Joon-myoung and Choi, Edward},
  journal={{NeurIPS}},
  volume={36},
  year={2024}
}

@article{Dataset-PTB-XL,
  title={PTB-XL, a large publicly available electrocardiography dataset},
  author={Wagner, Patrick and Strodthoff, Nils and Bousseljot, Ralf-Dieter and Kreiseler, Dieter and Lunze, Fatima I and Samek, Wojciech and Schaeffter, Tobias},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={1--15},
  year={2020}
}

@article{Dataset-ZuCo2,
    title={ZuCo 2.0: A dataset of physiological recordings during natural reading and annotation},
    author={Hollenstein, Nora and Troendle, Marius and Zhang, Ce and Langer, Nicolas},
    journal={ArXiv},
    volume={abs/1912.00903},
    year={2019}
}

@article{Dataset-MIMICIII,
    author={Johnson, Alistair and Pollard, Tom and Shen, Lu and Lehman, Li-wei and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo and Mark, Roger},
    year={2016},
    month={05},
    pages={160035},
    title={MIMIC-III, a freely accessible critical care database},
    volume={3},
    journal={Scientific Data}
}

@ARTICLE{Dataset-CirCor,
  author={Oliveira, Jorge and Renna, Francesco and Costa, Paulo Dias and Nogueira, Marcelo and Oliveira, Cristina and Ferreira, Carlos and Jorge, Al√≠pio and Mattos, Sandra and Hatem, Thamine and Tavares, Thiago and Elola, Andoni and Rad, Ali Bahrami and Sameni, Reza and Clifford, Gari D. and Coimbra, Miguel T.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={The CirCor DigiScope Dataset: From Murmur Detection to Murmur Classification}, 
  year={2022},
  volume={26},
  number={6},
  pages={2524-2535}}

@article{Dataset-PIXIU,
  title={Pixiu: A large language model, instruction data and evaluation benchmark for finance},
  author={Xie, Qianqian and Han, Weiguang and Zhang, Xiao and Lai, Yanzhao and Peng, Min and Lopez-Lira, Alejandro and Huang, Jimin},
  journal={ArXiv},
  volume={abs/2306.05443},
  year={2023}
}

@inproceedings{Dataset-MoAT,
  title={MoAT: Multi-Modal Augmented Time Series Forecasting},
  author={Lee, Geon and Yu, Wenchao and Cheng, Wei and Chen, Haifeng},
  booktitle ={{ICLR}},
  year={2024},
}

@article{Dataset-NASDAO100,
  title={A dual-stage attention-based recurrent neural network for time series prediction},
  author={Qin, Yao and Song, Dongjin and Chen, Haifeng and Cheng, Wei and Jiang, Guofei and Cottrell, Garrison},
  journal={ArXiv},
  volume={abs/1704.02971},
  year={2017}
}

@inproceedings{Dataset-StockNet,
  title={Stock movement prediction from tweets and historical prices},
  author={Xu, Yumo and Cohen, Shay B},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1970--1979},
  year={2018}
}

@inproceedings{Dataset-Ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={{CVPR}},
  pages={18995--19012},
  year={2022}
}

@inproceedings{Dataset-DeepsQA,
  title={Deepsqa: Understanding sensor data via question answering},
  author={Xing, Tianwei and Garcia, Luis and Cerutti, Federico and Kaplan, Lance and Preece, Alun and Srivastava, Mani},
  booktitle={{IoTDI}},
  pages={106--118},
  year={2021}
}

@article{Dataset-M4,
title={The M4 Competition: 100,000 time series and 61 forecasting methods},
journal={International Journal of Forecasting},
volume={36},
number={1},
pages={54-74},
year={2020},
author={Spyros Makridakis and Evangelos Spiliotis and Vassilios Assimakopoulos}
}

@misc{Dataset-UEA,
      title={The UEA multivariate time series classification archive, 2018}, 
      author={Anthony Bagnall and Hoang Anh Dau and Jason Lines and Michael Flynn and James Large and Aaron Bostrom and Paul Southam and Eamonn Keogh},
      year={2018},
      journal={ArXiv},
      volume={abs/1811.00075} 
}

@article{Dataset-UCR,
  title={The UCR time series archive},
  author={Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={6},
  number={6},
  pages={1293--1305},
  year={2019}
}

@misc{LLM-TS-Revisited,
      title={Revisited Large Language Model for Time Series Analysis through Modality Alignment}, 
      author={Liangwei Nathan Zheng and Chang George Dong and Wei Emma Zhang and Lin Yue and Miao Xu and Olaf Maennel and Weitong Chen},
      year={2024},
      journal={ArXiv},
      volume={abs/2410.12326}
}

@misc{LLM-TS-UnUseful,
      title={Are Large Language Models Useful for Time Series Data Analysis?}, 
      author={Francis Tang and Ying Ding},
      year={2024},
      journal={ArXiv},
      volume={abs/2412.12219}
}

@misc{DECA,
      title={Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series}, 
      author={Yuxiao Hu and Qian Li and Dongxiao Zhang and Jinyue Yan and Yuntian Chen},
      year={2025},
      journal={ArXiv},
      volume={abs/2501.03747}
}

@misc{Caption,
      title={Time Series Language Model for Descriptive Caption Generation}, 
      author={Mohamed Trabelsi and Aidan Boyd and Jin Cao and Huseyin Uzunalioglu},
      year={2025},
      journal={ArXiv},
      volume={abs/2501.01832} 
}

@misc{LTSM-Bundle,
      title={Understanding Different Design Choices in Training Large Time Series Models}, 
      author={Yu-Neng Chuang and Songchen Li and Jiayi Yuan and Guanchu Wang and Kwei-Herng Lai and Leisheng Yu and Sirui Ding and Chia-Yuan Chang and Qiaoyu Tan and Daochen Zha and Xia Hu},
      year={2024},
      journal={ArXiv},
      volume={abs/2406.14045} 
}

@misc{LSTPrompt,
      title={LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting}, 
      author={Haoxin Liu and Zhiyuan Zhao and Jindong Wang and Harshavardhan Kamarthi and B. Aditya Prakash},
      year={2024},
      journal={ArXiv},
      volume={abs/2402.16132}
}

@misc{InstructTime,
      title={Advancing Time Series Classification with Multimodal Language Modeling}, 
      author={Mingyue Cheng and Yiheng Chen and Qi Liu and Zhiding Liu and Yucong Luo},
      year={2024},
      journal={ArXiv},
      volume={abs/2403.12371}
}

@misc{CrossTimeNet,
      title={Cross-Domain Pre-training with Language Models for Transferable Time Series Representations}, 
      author={Mingyue Cheng and Xiaoyu Tao and Qi Liu and Hao Zhang and Yiheng Chen and Defu Lian},
      year={2024},
      journal={ArXiv},
      volume={abs/2403.12372}
}

@misc{UniTime,
      title={UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting}, 
      author={Xu Liu and Junfeng Hu and Yuan Li and Shizhe Diao and Yuxuan Liang and Bryan Hooi and Roger Zimmermann},
      year={2023},
      journal={ArXiv},
      volume={abs/2310.09751}
}

@misc{AnomalyLLM,
      title={Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection}, 
      author={Chen Liu and Shibo He and Qihang Zhou and Shizhong Li and Wenchao Meng},
      year={2024},
      journal={ArXiv},
      volume={abs/2401.15123}
}

@inproceedings{
Insight-Miner,
title={Insight Miner: A Large-scale Multimodal Model for Insight Mining from Time Series},
author={Yunkai Zhang and Yawen Zhang and Ming Zheng and Kezhen Chen and Chongyang Gao and Ruian Ge and Siyuan Teng and Amine Jelloul and Jinmeng Rao and Xiaoyuan Guo and Chiang-Wei Fang and Zeyu Zheng and Jie Yang},
booktitle={NeurIPS 2023 AI for Science Workshop},
year={2023}
}

@misc{SCRL-LG,
      title={Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction}, 
      author={Yujie Ding and Shuai Jia and Tianyi Ma and Bingcheng Mao and Xiuze Zhou and Liuliu Li and Dongming Han},
      year={2023},
      journal={ArXiv},
      volume={abs/2310.05627}
}

@misc{REALM,
      title={REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large Language Models}, 
      author={Yinghao Zhu and Changyu Ren and Shiyun Xie and Shukai Liu and Hangyuan Ji and Zixiang Wang and Tao Sun and Long He and Zhoujun Li and Xi Zhu and Chengwei Pan},
      year={2024},
      journal={ArXiv},
      volume={abs/2402.07016}
}

@misc{TS-HTFA,
      title={TS-HTFA: Advancing Time Series Forecasting via Hierarchical Text-Free Alignment with Large Language Models}, 
      author={Pengfei Wang and Huanran Zheng and Qi'ao Xu and Silong Dai and Yiqiao Wang and Wenjing Yue and Wei Zhu and Tianwen Qian and Xiaoling Wang},
      year={2025},
      journal={ArXiv},
      volume={abs/2409.14978}
}

@misc{Position-1,
      title={Position: What Can Large Language Models Tell Us about Time Series Analysis}, 
      author={Ming Jin and Yifan Zhang and Wei Chen and Kexin Zhang and Yuxuan Liang and Bin Yang and Jindong Wang and Shirui Pan and Qingsong Wen},
      year={2024},
      journal={ArXiv},
      volume={abs/2402.02713}
}

@misc{AutoGLM,
      title={AutoGLM: Autonomous Foundation Agents for GUIs}, 
      author={Xiao Liu and Bo Qin and Dongzhu Liang and Guang Dong and Hanyu Lai and Hanchen Zhang and Hanlin Zhao and Iat Long Iong and Jiadai Sun and Jiaqi Wang and Junjie Gao and Junjun Shan and Kangning Liu and Shudan Zhang and Shuntian Yao and Siyi Cheng and Wentao Yao and Wenyi Zhao and Xinghan Liu and Xinyi Liu and Xinying Chen and Xinyue Yang and Yang Yang and Yifan Xu and Yu Yang and Yujia Wang and Yulin Xu and Zehan Qi and Yuxiao Dong and Jie Tang},
      year={2024},
      journal={ArXiv},
      volume={abs/2411.00820}
}

@article{Survey_Agent,
   title={A survey on large language model based autonomous agents},
   volume={18},
   ISSN={2095-2236},
   DOI={10.1007/s11704-024-40231-1},
   number={6},
   journal={Frontiers of Computer Science},
   author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
   year={2024},
   month=mar
}

@article{VisionTS,
  author       = {Mouxiang Chen and
                  Lefei Shen and
                  Zhuo Li and
                  Xiaoyun Joy Wang and
                  Jianling Sun and
                  Chenghao Liu},
  title        = {VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time
                  Series Forecasters},
      year={2024},
      journal={ArXiv},
      volume={abs/2408.17253}
}

@inproceedings{TSasImages,
 author = {Li, Zekun and Li, Shiyang and Yan, Xifeng},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {49187--49204},
 title = {Time Series as Images: Vision Transformer for Irregularly Sampled Time Series},
 volume = {36},
 year = {2023}
}

@misc{Argos,
      title={Argos: Agentic Time-Series Anomaly Detection with Autonomous Rule Generation via Large Language Models}, 
      author={Yile Gu and Yifan Xiong and Jonathan Mace and Yuting Jiang and Yigong Hu and Baris Kasikci and Peng Cheng},
      year={2025},
      journal={ArXiv},
      volume={abs/2501.14170}
}

@misc{Pretained-MTS,
      title={Using Pre-trained LLMs for Multivariate Time Series Forecasting}, 
      author={Malcolm L. Wolff and Shenghao Yang and Kari Torkkola and Michael W. Mahoney},
      year={2025},
      journal={ArXiv},
      volume={abs/2501.06386}
}

@inproceedings{TS-Insights,
title={Insight Miner: A Large-scale Multimodal Model for Insight Mining from Time Series},
author={Yunkai Zhang and Yawen Zhang and Ming Zheng and others},
booktitle={NeurIPS 2023 AI for Science Workshop},
year={2023}
}

@misc{Position-2,
      title={Position: Empowering Time Series Reasoning with Multimodal LLMs}, 
      author={Yaxuan Kong and Yiyuan Yang and Shiyu Wang and others},
      year={2025},
      archivePrefix={ArXiv},
      volume={abs/2502.01477}
}

@article{CognitiveBrain,
  title={The neural architecture of language: Integrative modeling converges on predictive processing},
  author={Schrimpf, Martin and Blank, Idan Asher and Tuckute, Greta and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={45},
  pages={e2105646118},
  year={2021}
}

@INPROCEEDINGS{Noise,
  author={Hao, Xinli and Chen, Yile and others},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations}, 
  year={2024},
  volume={},
  number={},
  pages={570-583},
  keywords={Learning systems;Noise;Time series analysis;Stars;Transformers;Data engineering;Graph neural networks;Time series;Anomaly detection;AI for science},
  doi={10.1109/ICDE60146.2024.00050}}